{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport time\nfrom tqdm import tqdm\nimport random\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport PIL.Image\nfrom IPython.display import Image\nfrom sklearn.metrics import confusion_matrix\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import models,transforms,datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-13T07:39:44.184874Z","iopub.execute_input":"2022-09-13T07:39:44.185990Z","iopub.status.idle":"2022-09-13T07:39:46.812268Z","shell.execute_reply.started":"2022-09-13T07:39:44.185276Z","shell.execute_reply":"2022-09-13T07:39:46.811314Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#getting all the classes present in the dataset \npath_train = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train\"\nclasses = [c for c in os.listdir(path_train) if not c.startswith(\".\")]\nclasses.sort()\nprint(classes)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:39:46.813952Z","iopub.execute_input":"2022-09-13T07:39:46.814465Z","iopub.status.idle":"2022-09-13T07:39:46.833197Z","shell.execute_reply.started":"2022-09-13T07:39:46.814405Z","shell.execute_reply":"2022-09-13T07:39:46.832186Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#mapping all the classes to their meaning\nclass_dict = {0 : \"safe driving\",\n              1 : \"texting - right\",\n              2 : \"talking on the phone - right\",\n              3 : \"texting - left\",\n              4 : \"talking on the phone - left\",\n              5 : \"operating the radio\",\n              6 : \"drinking\",\n              7 : \"reaching behind\",\n              8 : \"hair and makeup\",\n              9 : \"talking to passenger\"}","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:39:46.834848Z","iopub.execute_input":"2022-09-13T07:39:46.835208Z","iopub.status.idle":"2022-09-13T07:39:46.840245Z","shell.execute_reply.started":"2022-09-13T07:39:46.835174Z","shell.execute_reply":"2022-09-13T07:39:46.839174Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Analyzing the dataset ","metadata":{}},{"cell_type":"code","source":"\nd = {\"img\" : [], \"class\" : []}\n#making a list of all the images and the classes that they belong to \nfor c in classes:\n    #get the image \n    imgs = [img for img in os.listdir(os.path.join(path_train,c)) if not img.startswith(\".\")]\n    #append the image name and class that it belongs to into a dictionary\n    for img in imgs:\n        d[\"img\"].append(img)\n        d[\"class\"].append(c)\ndf = pd.DataFrame(d)\n#create a count plot to analyze number of images in each class \nax = sns.countplot(data=df,x=\"class\")\nax.set(title=\"Classes distribution\")\nprint(\"Total number of training data :\",len(df))","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:39:46.842986Z","iopub.execute_input":"2022-09-13T07:39:46.844010Z","iopub.status.idle":"2022-09-13T07:39:51.045206Z","shell.execute_reply.started":"2022-09-13T07:39:46.843973Z","shell.execute_reply":"2022-09-13T07:39:51.044316Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Since the number of images in each class is not skewed we can use the same data.","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:39:51.046774Z","iopub.execute_input":"2022-09-13T07:39:51.047150Z","iopub.status.idle":"2022-09-13T07:39:51.060390Z","shell.execute_reply.started":"2022-09-13T07:39:51.047114Z","shell.execute_reply":"2022-09-13T07:39:51.059447Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"'''using the pytorch torchvision package to transform the images present\n1. To resize the image to (400,400)\n2. To rotate the image \n3. To convert all the images to a tensor '''\ntransform = transforms.Compose([transforms.Resize((400, 400)),\n                                 transforms.RandomRotation(10),\n                                 transforms.ToTensor()])","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:39:51.062145Z","iopub.execute_input":"2022-09-13T07:39:51.062759Z","iopub.status.idle":"2022-09-13T07:39:51.068185Z","shell.execute_reply.started":"2022-09-13T07:39:51.062724Z","shell.execute_reply":"2022-09-13T07:39:51.067275Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"'''\n1.Getting the Data \n2.Splitting the data for training and testing''' \n#data returns a tuple with(image_tensor,class)\ndata = datasets.ImageFolder(root = path_train, transform = transform)\n\ntotal_len = len(data)\ntraining_len = int(0.8*total_len)\ntesting_len = total_len - training_len\n\ntraining_data,testing_data = torch.utils.data.random_split(data,(training_len,testing_len))","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:39:51.069383Z","iopub.execute_input":"2022-09-13T07:39:51.070215Z","iopub.status.idle":"2022-09-13T07:40:15.855915Z","shell.execute_reply.started":"2022-09-13T07:39:51.070177Z","shell.execute_reply":"2022-09-13T07:40:15.854959Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"'''Create training and testing loaders to analyze the dataset'''\ntrain_loader = torch.utils.data.DataLoader(dataset=training_data,\n                                           batch_size=64,\n                                           shuffle=True,\n                                           drop_last=False)\ntest_loader = torch.utils.data.DataLoader(dataset=testing_data,\n                                          batch_size=64,\n                                          shuffle=False,\n                                          drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:40:15.860773Z","iopub.execute_input":"2022-09-13T07:40:15.862962Z","iopub.status.idle":"2022-09-13T07:40:15.871029Z","shell.execute_reply.started":"2022-09-13T07:40:15.862922Z","shell.execute_reply":"2022-09-13T07:40:15.869912Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"img,c = data[0]\nprint(img.shape)\nprint(\"Label:\", classes[c], f\"({class_dict[c]})\")\nplt.imshow(img.permute(1,2,0))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:40:15.875741Z","iopub.execute_input":"2022-09-13T07:40:15.878303Z","iopub.status.idle":"2022-09-13T07:40:16.243016Z","shell.execute_reply.started":"2022-09-13T07:40:15.878268Z","shell.execute_reply":"2022-09-13T07:40:16.242125Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"'''Looking at one batch of data. Change train_loader to test_loader to see the batch from the test set'''\nloader,labels = next(iter(train_loader))\nprint(loader.shape)\nprint(labels.view(8,8))\nplt.figure(figsize=(16,16))\nplt.imshow(torchvision.utils.make_grid(loader,nrow=8).permute((1,2,0)))\n","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:40:16.246719Z","iopub.execute_input":"2022-09-13T07:40:16.248039Z","iopub.status.idle":"2022-09-13T07:40:21.179853Z","shell.execute_reply.started":"2022-09-13T07:40:16.247997Z","shell.execute_reply":"2022-09-13T07:40:21.177493Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Creating the Model","metadata":{}},{"cell_type":"code","source":"#checking for gpu\ndevice = torch.device(\"cuda:0\")\nprint(device)\nprint(torch.cuda.get_device_name(device))","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:40:21.181698Z","iopub.execute_input":"2022-09-13T07:40:21.182525Z","iopub.status.idle":"2022-09-13T07:40:21.256655Z","shell.execute_reply.started":"2022-09-13T07:40:21.182483Z","shell.execute_reply":"2022-09-13T07:40:21.255461Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#we nomalize the data because neural networks works better with normalized data\ntransform = transforms.Compose([transforms.Resize((400, 400)),\n                           transforms.RandomRotation(10),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n                          ])","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:40:21.258652Z","iopub.execute_input":"2022-09-13T07:40:21.259614Z","iopub.status.idle":"2022-09-13T07:40:21.268944Z","shell.execute_reply.started":"2022-09-13T07:40:21.259445Z","shell.execute_reply":"2022-09-13T07:40:21.268074Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"'''\n1.Getting the Data \n2.Splitting the data for training and testing''' \ndata = datasets.ImageFolder(root = path_train, transform = transform)\n\ntotal_len = len(data)\ntraining_len = int(0.8*total_len)\ntesting_len = total_len - training_len\n\ntraining_data,testing_data = torch.utils.data.random_split(data,(training_len,testing_len))","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:40:21.272668Z","iopub.execute_input":"2022-09-13T07:40:21.274223Z","iopub.status.idle":"2022-09-13T07:40:24.869064Z","shell.execute_reply.started":"2022-09-13T07:40:21.274183Z","shell.execute_reply":"2022-09-13T07:40:24.868057Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"'''Create training and testing loaders to analyze the dataset'''\ntrain_loader = torch.utils.data.DataLoader(dataset=training_data,\n                                           batch_size=32,\n                                           shuffle=True,\n                                           drop_last=False,\n                                           num_workers=2)\ntest_loader = torch.utils.data.DataLoader(dataset=testing_data,\n                                          batch_size=32,\n                                          shuffle=False,\n                                          drop_last=False,\n                                          num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:40:24.871580Z","iopub.execute_input":"2022-09-13T07:40:24.872177Z","iopub.status.idle":"2022-09-13T07:40:24.880382Z","shell.execute_reply.started":"2022-09-13T07:40:24.872138Z","shell.execute_reply":"2022-09-13T07:40:24.879465Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, n_epochs = 5):\n    \n    losses = []\n    accuracies = []\n    test_accuracies = []\n    # set the model to train mode initially\n    model.train()\n    for epoch in tqdm(range(n_epochs)):\n        since = time.time()\n        running_loss = 0.0\n        running_correct = 0.0\n        for data in train_loader:\n\n            # get the inputs and assign them to cuda\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            \n            # forward + backward + optimize\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            # calculate the loss/acc later\n            running_loss += loss.item()\n            running_correct += (labels==predicted).sum().item()\n\n        epoch_duration = time.time()-since\n        epoch_loss = running_loss/len(train_loader)\n        epoch_acc = 100/32*running_correct/len(train_loader)\n\n        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n        \n        losses.append(epoch_loss)\n        accuracies.append(epoch_acc)\n        \n        # switch the model to eval mode to evaluate on test data\n        model.eval()\n        test_acc = eval_model(model)\n        test_accuracies.append(test_acc)\n        \n        # re-set the model to train mode after validating\n        model.train()\n        scheduler.step(test_acc)\n        since = time.time()\n    print('Finished Training')\n    return model, losses, accuracies, test_accuracies","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:40:24.882298Z","iopub.execute_input":"2022-09-13T07:40:24.883119Z","iopub.status.idle":"2022-09-13T07:40:24.895207Z","shell.execute_reply.started":"2022-09-13T07:40:24.883080Z","shell.execute_reply":"2022-09-13T07:40:24.894027Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def eval_model(model):\n    correct = 0.0\n    total = 0.0\n    with torch.no_grad():\n        for i, data in enumerate(test_loader, 0):\n            images, labels = data\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model_ft(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    test_acc = 100.0 * correct / total\n    print('Accuracy of the network on the test images: %d %%' % (\n        test_acc))\n    return test_acc","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:40:24.896912Z","iopub.execute_input":"2022-09-13T07:40:24.897597Z","iopub.status.idle":"2022-09-13T07:40:24.909604Z","shell.execute_reply.started":"2022-09-13T07:40:24.897538Z","shell.execute_reply":"2022-09-13T07:40:24.908470Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#we are getting the restnet50 and changing the last fc layer to take in classes 10.\nmodel_ft = models.resnet50(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n\nmodel_ft.fc = nn.Linear(num_ftrs, 10) #No. of classes = 10\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\nlrscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:40:24.911165Z","iopub.execute_input":"2022-09-13T07:40:24.911917Z","iopub.status.idle":"2022-09-13T07:40:39.164782Z","shell.execute_reply.started":"2022-09-13T07:40:24.911881Z","shell.execute_reply":"2022-09-13T07:40:39.163804Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# takes around 5-6 minutes per epoch with GPU\nmodel_ft, training_losses, training_accs, test_accs = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=2)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:40:39.166166Z","iopub.execute_input":"2022-09-13T07:40:39.166638Z","iopub.status.idle":"2022-09-13T07:53:24.460961Z","shell.execute_reply.started":"2022-09-13T07:40:39.166600Z","shell.execute_reply":"2022-09-13T07:53:24.459714Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"plt.title('Training losses')\nplt.plot(training_losses)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:53:24.463188Z","iopub.execute_input":"2022-09-13T07:53:24.463941Z","iopub.status.idle":"2022-09-13T07:53:24.646394Z","shell.execute_reply.started":"2022-09-13T07:53:24.463894Z","shell.execute_reply":"2022-09-13T07:53:24.645454Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"plt.title('Training Accuracy')\nplt.plot(training_accs)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:53:24.648621Z","iopub.execute_input":"2022-09-13T07:53:24.648964Z","iopub.status.idle":"2022-09-13T07:53:24.841570Z","shell.execute_reply.started":"2022-09-13T07:53:24.648929Z","shell.execute_reply":"2022-09-13T07:53:24.840708Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"plt.title('Test Accuracy')\nplt.plot(test_accs)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:53:24.842878Z","iopub.execute_input":"2022-09-13T07:53:24.843219Z","iopub.status.idle":"2022-09-13T07:53:25.032174Z","shell.execute_reply.started":"2022-09-13T07:53:24.843184Z","shell.execute_reply":"2022-09-13T07:53:25.031230Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"torch.save(model_ft.state_dict(), \"saved_model.pth\")","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:53:25.033464Z","iopub.execute_input":"2022-09-13T07:53:25.034268Z","iopub.status.idle":"2022-09-13T07:53:25.226149Z","shell.execute_reply.started":"2022-09-13T07:53:25.034229Z","shell.execute_reply":"2022-09-13T07:53:25.225102Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = models.resnet50()\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 10)\nmodel.load_state_dict(torch.load(\"./saved_model.pth\"))\nmodel.eval()\nmodel.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:53:25.227603Z","iopub.execute_input":"2022-09-13T07:53:25.227985Z","iopub.status.idle":"2022-09-13T07:53:25.852526Z","shell.execute_reply.started":"2022-09-13T07:53:25.227948Z","shell.execute_reply":"2022-09-13T07:53:25.851564Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#getting all the image names in a sorted fashion\npath_test = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/test\"\nlist_img_test = [img for img in os.listdir(path_test) if not img.startswith(\".\")]\nlist_img_test.sort()","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:53:25.854206Z","iopub.execute_input":"2022-09-13T07:53:25.854920Z","iopub.status.idle":"2022-09-13T07:53:28.106404Z","shell.execute_reply.started":"2022-09-13T07:53:25.854880Z","shell.execute_reply":"2022-09-13T07:53:28.105255Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"file = random.choice(list_img_test)\nim_path = os.path.join(path_test,file)\ndisplay(Image(filename=im_path))\n","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:53:28.107741Z","iopub.execute_input":"2022-09-13T07:53:28.108118Z","iopub.status.idle":"2022-09-13T07:53:28.126776Z","shell.execute_reply.started":"2022-09-13T07:53:28.108075Z","shell.execute_reply":"2022-09-13T07:53:28.125885Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"with PIL.Image.open(im_path) as im:\n    im = transform(im)\n    im = im.unsqueeze(0)\n    output = model(im.cuda())\n    proba = nn.Softmax(dim=1)(output)\n    proba = [round(float(elem),4) for elem in proba[0]]\n    print(proba)\n    print(\"Predicted class:\",class_dict[proba.index(max(proba))])\n    print(\"Confidence:\",max(proba))\n    proba2 = proba.copy()\n    proba2[proba2.index(max(proba2))] = 0.\n    print(\"2nd answer:\",class_dict[proba2.index(max(proba2))])\n    print(\"Confidence:\",max(proba2))","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:53:28.128273Z","iopub.execute_input":"2022-09-13T07:53:28.128628Z","iopub.status.idle":"2022-09-13T07:53:28.172420Z","shell.execute_reply.started":"2022-09-13T07:53:28.128593Z","shell.execute_reply":"2022-09-13T07:53:28.171360Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#Testing the divided test data\n\ndef true_pred(test_data,model):\n    y_true = []\n    y_pred = []\n    n = len(test_data)\n    sum = 0\n    with torch.no_grad():\n        for x,y in tqdm(test_data):\n            x = x.to(device)\n            pred = torch.argmax(model(x),dim=1)\n            y_true.extend(list(np.array(y)))\n            y_pred.extend(list(np.array(pred.cpu())))\n    return y_true,y_pred","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:56:07.817085Z","iopub.execute_input":"2022-09-13T07:56:07.817583Z","iopub.status.idle":"2022-09-13T07:56:07.833068Z","shell.execute_reply.started":"2022-09-13T07:56:07.817535Z","shell.execute_reply":"2022-09-13T07:56:07.831743Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"y_true,y_pred = true_pred(test_loader,model)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:56:20.648100Z","iopub.execute_input":"2022-09-13T07:56:20.648483Z","iopub.status.idle":"2022-09-13T07:57:17.449706Z","shell.execute_reply.started":"2022-09-13T07:56:20.648447Z","shell.execute_reply":"2022-09-13T07:57:17.448610Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"m = confusion_matrix(y_true, y_pred)\nm  = m.astype('float') / m.sum(axis=1)[:, np.newaxis]","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:57:35.428734Z","iopub.execute_input":"2022-09-13T07:57:35.429192Z","iopub.status.idle":"2022-09-13T07:57:35.451618Z","shell.execute_reply.started":"2022-09-13T07:57:35.429142Z","shell.execute_reply":"2022-09-13T07:57:35.450466Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(m)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T07:58:07.470150Z","iopub.execute_input":"2022-09-13T07:58:07.471159Z","iopub.status.idle":"2022-09-13T07:58:07.761327Z","shell.execute_reply.started":"2022-09-13T07:58:07.471109Z","shell.execute_reply":"2022-09-13T07:58:07.760300Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"Creating a test directory to make the predictions fast and ","metadata":{}},{"cell_type":"code","source":"os.mkdir(\"/kaggle/working/test\")","metadata":{"execution":{"iopub.status.busy":"2022-09-13T08:02:40.030131Z","iopub.execute_input":"2022-09-13T08:02:40.030544Z","iopub.status.idle":"2022-09-13T08:02:40.036433Z","shell.execute_reply.started":"2022-09-13T08:02:40.030509Z","shell.execute_reply":"2022-09-13T08:02:40.035394Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"for img in tqdm(list_img_test):\n    os.mkdir(\"/kaggle/working/test/\"+img[:-4])\n    source = path_test+\"/\"+img\n    destination = \"/kaggle/working/test/\"+img[:-4]+\"/\"+img\n    shutil.copy(source, destination)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T08:03:27.563001Z","iopub.execute_input":"2022-09-13T08:03:27.563482Z","iopub.status.idle":"2022-09-13T08:15:54.669585Z","shell.execute_reply.started":"2022-09-13T08:03:27.563403Z","shell.execute_reply":"2022-09-13T08:15:54.668595Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"transform_test = transforms.Compose([transforms.Resize((400, 400)),\n                                     #transforms.RandomRotation(10),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n                               ])","metadata":{"execution":{"iopub.status.busy":"2022-09-13T08:17:39.567232Z","iopub.execute_input":"2022-09-13T08:17:39.567596Z","iopub.status.idle":"2022-09-13T08:17:39.573897Z","shell.execute_reply.started":"2022-09-13T08:17:39.567563Z","shell.execute_reply":"2022-09-13T08:17:39.572846Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"datatest = datasets.ImageFolder(root = \"/kaggle/working/test\",\n                                transform = transform_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T08:17:58.526571Z","iopub.execute_input":"2022-09-13T08:17:58.526939Z","iopub.status.idle":"2022-09-13T08:18:00.770010Z","shell.execute_reply.started":"2022-09-13T08:17:58.526906Z","shell.execute_reply":"2022-09-13T08:18:00.769008Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"loader = torch.utils.data.DataLoader(dataset=datatest,\n                                     batch_size=16,\n                                     shuffle=False,\n                                     drop_last=False,\n                                     num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T08:20:01.306263Z","iopub.execute_input":"2022-09-13T08:20:01.307395Z","iopub.status.idle":"2022-09-13T08:20:01.320044Z","shell.execute_reply.started":"2022-09-13T08:20:01.307355Z","shell.execute_reply":"2022-09-13T08:20:01.318998Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"x,y = next(iter(loader))\nprint(x.shape)\nprint(y)\nplt.figure(figsize=(16,16))\nplt.imshow(torchvision.utils.make_grid(x,nrow=8).permute((1,2,0)))\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-13T08:20:34.795992Z","iopub.execute_input":"2022-09-13T08:20:34.796360Z","iopub.status.idle":"2022-09-13T08:20:36.283251Z","shell.execute_reply.started":"2022-09-13T08:20:34.796326Z","shell.execute_reply":"2022-09-13T08:20:36.282268Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/state-farm-distracted-driver-detection/sample_submission.csv\",index_col = 0)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T08:21:10.404348Z","iopub.execute_input":"2022-09-13T08:21:10.405153Z","iopub.status.idle":"2022-09-13T08:21:10.560218Z","shell.execute_reply.started":"2022-09-13T08:21:10.405109Z","shell.execute_reply":"2022-09-13T08:21:10.559251Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"line = 0\nfor x,y in tqdm(loader,total = len(loader)) :\n    output = model_ft(x.cuda())\n    output = nn.Softmax(dim=1)(output)\n    for i in range(len(output)) :\n        proba = [float(elem) for elem in output[i]]\n        df.iloc[line][:]=proba\n        line += 1","metadata":{"execution":{"iopub.status.busy":"2022-09-13T08:21:41.963093Z","iopub.execute_input":"2022-09-13T08:21:41.963482Z","iopub.status.idle":"2022-09-13T08:38:02.630094Z","shell.execute_reply.started":"2022-09-13T08:21:41.963445Z","shell.execute_reply":"2022-09-13T08:38:02.628928Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-13T08:52:38.140041Z","iopub.execute_input":"2022-09-13T08:52:38.140530Z","iopub.status.idle":"2022-09-13T08:52:38.170763Z","shell.execute_reply.started":"2022-09-13T08:52:38.140485Z","shell.execute_reply":"2022-09-13T08:52:38.169646Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"#removing all the files we created \nfor img in tqdm(list_img_test):\n    os.remove(\"/kaggle/working/test/\"+img[:-4]+\"/\"+img)\n    os.rmdir(\"/kaggle/working/test/\"+img[:-4])","metadata":{"execution":{"iopub.status.busy":"2022-09-13T08:56:38.792225Z","iopub.execute_input":"2022-09-13T08:56:38.792589Z","iopub.status.idle":"2022-09-13T08:56:43.338719Z","shell.execute_reply.started":"2022-09-13T08:56:38.792559Z","shell.execute_reply":"2022-09-13T08:56:43.337607Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"os.rmdir(\"/kaggle/working/test\")","metadata":{"execution":{"iopub.status.busy":"2022-09-13T08:56:46.835210Z","iopub.execute_input":"2022-09-13T08:56:46.835587Z","iopub.status.idle":"2022-09-13T08:56:46.893083Z","shell.execute_reply.started":"2022-09-13T08:56:46.835555Z","shell.execute_reply":"2022-09-13T08:56:46.892145Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"df.to_csv(\"/kaggle/working/submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-09-13T08:56:54.878061Z","iopub.execute_input":"2022-09-13T08:56:54.878451Z","iopub.status.idle":"2022-09-13T08:56:56.001849Z","shell.execute_reply.started":"2022-09-13T08:56:54.878399Z","shell.execute_reply":"2022-09-13T08:56:56.000836Z"},"trusted":true},"execution_count":48,"outputs":[]}]}